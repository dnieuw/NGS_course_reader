# Automating data analysis

## Running the automated Nanopore metagenomic analysis workflow

Similar to the amplicon workflow we have created a Snakemake workflow for the metagenomic analysis steps from the previous section.

## Preparing to run the workflow

The workflow takes an input "sample_config" tabular file and based on this file it will process all samples in parallel and automatically.

The tabular config file has the following structure:

| UniqueID | FASTQ_path |
|----------|------------|
| BC01     | barcode01  |
| BC02     | barcode02  |

::: {.callout-warning}
# Attention!
Make sure that the first line contains the _exact headers_ as shown in the table above, you can find an example file in the course material.
:::

- `UniqueID`: This is the unique name used in the workflow to keep track of your sample while processing, please use a simple and unique name (e.g. `BC01`, etc.)
- `FASTQ_path`: This is the folder location of all raw `.fastq.gz` file for a single sample, no need to use `cat` to paste them together.

After filling out the tablular file, we can create a directory (folder) for the results with the following process.

First check your current directory with the `pwd` command:

``` bash
pwd
```

Change your current directory using `cd` if needed:

``` bash
cd /{folder1}/{folder2}
```

Then create the new directory using the `mkdir` command:

``` bash
mkdir results
```

This creates a new directory at the current location. Move the `sample_config.tsv` file to the results directory using the `mv` (move) command:

``` bash
mv sample_config.tsv results
```

::: {.callout-tip}
If you get a "file not found" error after changing your directory (`cd`) you may need to write the complete path of your sample_config.tsv file e.g `mv /home/david/Documents/sample_config.tsv results`
:::

After preparing the results directory we have to make sure that we have activated the `viroscience_env` conda environment and check if the command line has `(viroscience_env)` in front.

Next, run the `ls` command to list the files in the current directory and check if the `amplicon_workflow.smk`, `GCF_000001405.26_GRCh38_genomic.fna.gz`, `ncbi_viral_complete_human.fasta` database files and `new_taxdump.tar.gz` files are present.

::: {.callout-warning}
# Important!
Also make sure to edit the location of the `post_process_annotation.py` script to where you have stored in on your computer! 

_Open the `amplicon_workflow.smk` file, search for `post_process_annotation.py` and edit the path!_
:::

## Running the workflow

We can do a last optional check if everything is fine and the workflow can be executed by performing a "dryrun" using the `--dryrun` parameter:

``` bash
snakemake \
--snakefile \
viral_metagenome_workflow.smk \
--directory {ourdir} \
--configfile sample_config={config} host_reference=../GCF_000001405.26_GRCh38_genomic.fna.gz database=../ncbi_viral_complete_human.fasta taxdump=../new_taxdump.tar.gz \
--cores {threads} \
--dryrun
```

- `{outdir}`: This is the directory we have just created (e.g. `results`)
- `{config}`: This is the config file we have created previously.

If there are no errors we can execute the full workflow by excluding the `--dryrun` parameter:

``` bash
snakemake \
--snakefile \
viral_metagenome_workflow.smk \
--directory {ourdir} \
--configfile sample_config={config} host_reference=../GCF_000001405.26_GRCh38_genomic.fna.gz database=../ncbi_viral_complete_human.fasta taxdump=../new_taxdump.tar.gz \
--cores {threads}
```

::: {.callout-note}
The workflow, with a single sample, should finish in a about 20 minutes on your laptop. Next we will have a look at working on the HPC to run the analysis.
:::
